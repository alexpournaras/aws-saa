Amazon S3

advertised as 'infinitelly scaling storage'

use cases:
backup and storage
disaster recovery
archive
hybris cloud storage
application hosting
media hosting (video, images, files)
data lakes & big data analytics
software delivery
static website

s3 buckets

* store objects (files) in buckets (directories/folders)
* buckets must have a globally unique name (accross all regions and all users)
* buckets are defind in region level!! (important)
* naming convention: 
    - no uppercase, no underscore
    - 3-63 characters long
    - not an ip
    - must start with lowecase letter or number
    - must NOT start with the prefix xn--
    - must Not end with the suffix -s3alias

s3 objects

objects (files) have a key. the key is the FULL PATH

s3://my-bucket/[my_file.txt]
s3://my-bucket/[my_folder/another_folder/my_file.txt]

key is composed of prefix: my_folder/another_folder/
and the object name: my_file.txt

there is no concept of directiories!!! the ui seems like it but its not!!! (important)

object values are the content:
- max object size is 5TB
- if uploading more than 5GB, must use `multi-part upload`

they can have metadata, tags and version id if versioning is enabled

when objects are not for public, their public url will not work, unless we press the open button that will open the url but with a pre signed signature that will basically have our credentials encrypted, therefore it will allow us to see the file.

--

security

* user based: iam policies -> which is api calls should be allowed for a specific user from iam

* resource-based:
    - bucket policeis => bucket wide rules from the s3 console - allows cross account
    - object access control list (acl) -> finer grain (can be disabled)
    - bucket access control list (acl) -> less common (can be disabled)

* an iam pricipal can access s3 object if:
the user iam permissions ALLOW it OR the resource policy ALLOWS its, AND there no explicit DENY.

* encryption

s3 bucket policies:

json documents
resources: buckets and objects
effect: allow/deny
actions: set of api calls to allo or deny
principal: the account or user to apply policy to

use s3 bucket for policy to:
* grant public access to the bucket
* froce objects to be encrypted at upload
* grant access to another account (cross-account)

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "PublicRead",
      "Effect": "Allow",
      "Principal": "*",
      "Action": [
        "s3:GetObject",
      ],
      "Resource": ["arn:aws:s3:::mybucket/*"]
    }
  ]
}
```

Allow (effect) everyone (principal) to see objects (action) from the s3 bucket 'mybucket' (resource)

* when a website user needs to have access to an object, we create a bucket policy to allow public access
* when an iam user needs to have access to an object, we attack an iam policy that will allow user to see this s3 object
* when ec2 needs to have access to an s3 object, we attach an iam instance Role that have the corresponding iam permissions
* when there is another iam user from another aws account and we want to give access, we create a bucket policy that allows cross-account

bucket settings for block public access
* there is a list of checkboxes that are enabled to block public access
* these settings were created to prevent company data leaks
* if we want the data in our bucket to stay private, leave these checkboxes on
* can be set at the account level.

--

versioning

* is enabled at bucket level
* same key overwrite will change the version: 1, 2, 3...
* its best practive to version the buckets
    - protect agains unintened deletes
    - ability to restore previous version (roll back)

* any file that is not versioned will have version 'null'.
* suspeneding versioning does not delete the previous versions

* to roleback, we delete the latest version.
* if we delete a file with no previous versions, it will create a delete marker. to bring it back, we delete the delete marker.

--
replication

* must enable versioning in source and destination
* cross-region replication (CRR)
* same-region replication (SRR)
* buckets can be in different AWS accounts
* copying is ASNYCRONOUS
* must give proper iam permissions to s3

use cases:
crr: compiance, lower latency access, replication accros accounts
srr: log aggregation, live replication between production and test accounts (for test environments)

* after we enable replication, only new objects are replicated
* optionally we can replicate existing objects using s3 batch replication
* for DELETE operations: we can replicate delete markers from source to target (optional setting), deletions with a version id are not replicated to avoid malicious deletes!!!! (important) (replication rule -> delete marker replication)
* there is no chaining of replications. if 1 replicate to 2 and 2 to 3, then 1 will NOT replicate to 3.